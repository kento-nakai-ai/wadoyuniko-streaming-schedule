# ç‰¹å…¸38: ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ã‚­ãƒ«å®Œå…¨ãƒã‚¹ã‚¿ãƒ¼ã‚¬ã‚¤ãƒ‰

## ğŸ¯ æ¦‚è¦
AIé§†å‹•é–‹ç™ºã«ãŠã‘ã‚‹ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ã‚­ãƒ«ã‚’ç¶²ç¾…çš„ã«ç¿’å¾—ã™ã‚‹ãŸã‚ã®å®Ÿè·µçš„ã‚¬ã‚¤ãƒ‰ã€‚AWSã€Azureã€GCPã®ä¸»è¦ã‚µãƒ¼ãƒ“ã‚¹ã‹ã‚‰ã€Kubernetesã€Dockerã€Infrastructure as Codeã¾ã§ã€ç¾ä»£çš„ãªã‚¯ãƒ©ã‚¦ãƒ‰ãƒã‚¤ãƒ†ã‚£ãƒ–é–‹ç™ºã«å¿…è¦ãªã‚¹ã‚­ãƒ«ã‚’ä½“ç³»çš„ã«å­¦ç¿’ã§ãã¾ã™ã€‚

## ğŸ“‹ å­¦ç¿’ç›®æ¨™
- [ ] ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã®åŸºç¤æ¦‚å¿µã‚’ç†è§£ã™ã‚‹
- [ ] AWS/Azure/GCPã®ä¸»è¦ã‚µãƒ¼ãƒ“ã‚¹ã‚’ç¿’å¾—ã™ã‚‹
- [ ] Dockerã‚³ãƒ³ãƒ†ãƒŠæŠ€è¡“ã‚’ãƒã‚¹ã‚¿ãƒ¼ã™ã‚‹
- [ ] Kubernetesã§ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè·µã™ã‚‹
- [ ] Infrastructure as Code (IaC)ã‚’å®Ÿè£…ã™ã‚‹
- [ ] CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹
- [ ] ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ­ã‚°ç®¡ç†ã‚’å®Ÿè£…ã™ã‚‹
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚’ç¢ºä¿ã™ã‚‹

## ğŸš€ Phase 1: ã‚¯ãƒ©ã‚¦ãƒ‰åŸºç¤ã¨AWSå…¥é–€

### 1.1 ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°åŸºç¤

```python
import boto3
import json
from datetime import datetime, timedelta
import pandas as pd
import matplotlib.pyplot as plt

class CloudFoundations:
    """
    ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®åŸºç¤æ¦‚å¿µã¨å®Ÿè£…
    """
    
    def __init__(self):
        self.cloud_services = {
            'compute': ['EC2', 'Lambda', 'ECS', 'EKS'],
            'storage': ['S3', 'EBS', 'EFS', 'Glacier'],
            'database': ['RDS', 'DynamoDB', 'Redshift', 'ElastiCache'],
            'networking': ['VPC', 'CloudFront', 'Route53', 'ELB'],
            'security': ['IAM', 'KMS', 'Secrets Manager', 'WAF'],
            'monitoring': ['CloudWatch', 'X-Ray', 'CloudTrail', 'Config']
        }
    
    def explain_cloud_models(self):
        """ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜"""
        models = {
            'IaaS': {
                'description': 'Infrastructure as a Service',
                'examples': ['AWS EC2', 'Azure VMs', 'GCP Compute Engine'],
                'control_level': 'OS, Runtime, Middleware, Data, Applications',
                'use_cases': ['Legacy migration', 'Development environments', 'Custom configurations']
            },
            'PaaS': {
                'description': 'Platform as a Service',
                'examples': ['AWS Elastic Beanstalk', 'Azure App Service', 'Google App Engine'],
                'control_level': 'Data, Applications',
                'use_cases': ['Web applications', 'API development', 'Rapid prototyping']
            },
            'SaaS': {
                'description': 'Software as a Service',
                'examples': ['Salesforce', 'Office 365', 'Google Workspace'],
                'control_level': 'Configuration only',
                'use_cases': ['Business applications', 'Collaboration', 'End-user services']
            }
        }
        
        for model, details in models.items():
            print(f"\n=== {model} ({details['description']}) ===")
            print(f"åˆ¶å¾¡ãƒ¬ãƒ™ãƒ«: {details['control_level']}")
            print(f"ä¾‹: {', '.join(details['examples'])}")
            print(f"ç”¨é€”: {', '.join(details['use_cases'])}")
        
        return models
    
    def aws_service_overview(self):
        """AWSä¸»è¦ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦"""
        for category, services in self.cloud_services.items():
            print(f"\n=== {category.upper()} ===")
            for service in services:
                print(f"  â€¢ {service}")
        
        # ã‚µãƒ¼ãƒ“ã‚¹é¸æŠã‚¬ã‚¤ãƒ‰
        selection_guide = {
            'compute': {
                'EC2': 'ãƒ•ãƒ«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãŒå¿…è¦ãªå ´åˆ',
                'Lambda': 'ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã€ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•',
                'ECS': 'Dockerã‚³ãƒ³ãƒ†ãƒŠç®¡ç†',
                'EKS': 'Kubernetesç®¡ç†'
            },
            'storage': {
                'S3': 'ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã€é™çš„ã‚µã‚¤ãƒˆ',
                'EBS': 'EC2ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸',
                'EFS': 'NFSãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ',
                'Glacier': 'é•·æœŸã‚¢ãƒ¼ã‚«ã‚¤ãƒ–'
            },
            'database': {
                'RDS': 'ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«DBç®¡ç†',
                'DynamoDB': 'NoSQLã€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹',
                'Redshift': 'ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹',
                'ElastiCache': 'ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥'
            }
        }
        
        print("\n=== ã‚µãƒ¼ãƒ“ã‚¹é¸æŠã‚¬ã‚¤ãƒ‰ ===")
        for category, services in selection_guide.items():
            print(f"\n{category.upper()}:")
            for service, use_case in services.items():
                print(f"  {service}: {use_case}")

class AWSHandsOn:
    """
    AWSå®Ÿè·µãƒãƒ³ã‚ºã‚ªãƒ³
    """
    
    def __init__(self, region='us-east-1'):
        # æ³¨æ„: å®Ÿéš›ã®AWSã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«ãŒå¿…è¦
        # self.session = boto3.Session(region_name=region)
        # self.ec2 = self.session.client('ec2')
        # self.s3 = self.session.client('s3')
        # self.lambda_client = self.session.client('lambda')
        
        # ãƒ‡ãƒ¢ç”¨ã®æ¨¡æ“¬å®Ÿè£…
        self.region = region
        self.mock_resources = {}
        
    def mock_ec2_operations(self):
        """EC2æ“ä½œã®ãƒ‡ãƒ¢å®Ÿè£…"""
        print("=== EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç®¡ç† ===")
        
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹èµ·å‹•ã®ä¾‹
        instance_config = {
            'ImageId': 'ami-12345678',  # Amazon Linux 2
            'InstanceType': 't3.micro',
            'MinCount': 1,
            'MaxCount': 1,
            'SecurityGroupIds': ['sg-12345678'],
            'SubnetId': 'subnet-12345678',
            'UserData': '''#!/bin/bash
yum update -y
yum install -y docker
systemctl start docker
systemctl enable docker
usermod -a -G docker ec2-user
'''
        }
        
        print("ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹è¨­å®š:")
        for key, value in instance_config.items():
            print(f"  {key}: {value}")
        
        # å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ä¾‹
        ec2_code = '''
# å®Ÿéš›ã®EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹èµ·å‹•ã‚³ãƒ¼ãƒ‰
response = ec2.run_instances(**instance_config)
instance_id = response['Instances'][0]['InstanceId']
print(f"ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹èµ·å‹•: {instance_id}")

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¸€è¦§å–å¾—
response = ec2.describe_instances()
for reservation in response['Reservations']:
    for instance in reservation['Instances']:
        print(f"ID: {instance['InstanceId']}, State: {instance['State']['Name']}")

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åœæ­¢
ec2.stop_instances(InstanceIds=[instance_id])
'''
        
        print("\nå®Ÿè£…ä¾‹:")
        print(ec2_code)
        
        return instance_config
    
    def mock_s3_operations(self):
        """S3æ“ä½œã®ãƒ‡ãƒ¢å®Ÿè£…"""
        print("\n=== S3ãƒã‚±ãƒƒãƒˆç®¡ç† ===")
        
        s3_operations = {
            'bucket_creation': '''
# ãƒã‚±ãƒƒãƒˆä½œæˆ
bucket_name = 'my-unique-bucket-name'
s3.create_bucket(Bucket=bucket_name)
''',
            'file_upload': '''
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
s3.upload_file('local_file.txt', bucket_name, 'remote_file.txt')

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
s3.upload_file(
    'data.csv',
    bucket_name,
    'data/data.csv',
    ExtraArgs={
        'Metadata': {'source': 'analytics', 'version': '1.0'},
        'ContentType': 'text/csv'
    }
)
''',
            'file_download': '''
# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
s3.download_file(bucket_name, 'data/data.csv', 'local_data.csv')

# ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§
response = s3.list_objects_v2(Bucket=bucket_name, Prefix='data/')
for obj in response.get('Contents', []):
    print(f"Key: {obj['Key']}, Size: {obj['Size']}")
''',
            'lifecycle_policy': '''
# ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒãƒªã‚·ãƒ¼è¨­å®š
lifecycle_config = {
    'Rules': [
        {
            'ID': 'TransitionRule',
            'Status': 'Enabled',
            'Transitions': [
                {
                    'Days': 30,
                    'StorageClass': 'STANDARD_IA'
                },
                {
                    'Days': 90,
                    'StorageClass': 'GLACIER'
                }
            ]
        }
    ]
}
s3.put_bucket_lifecycle_configuration(
    Bucket=bucket_name,
    LifecycleConfiguration=lifecycle_config
)
'''
        }
        
        for operation, code in s3_operations.items():
            print(f"\n{operation}:")
            print(code)
        
        return s3_operations
    
    def mock_lambda_function(self):
        """Lambdaé–¢æ•°ã®ãƒ‡ãƒ¢å®Ÿè£…"""
        print("\n=== Lambdaé–¢æ•°ç®¡ç† ===")
        
        # Lambdaé–¢æ•°ã‚³ãƒ¼ãƒ‰ä¾‹
        lambda_code = '''
import json
import boto3
from datetime import datetime

def lambda_handler(event, context):
    """
    S3ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ç”¨Lambdaé–¢æ•°
    """
    s3 = boto3.client('s3')
    
    # S3ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰æƒ…å ±æŠ½å‡º
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']
        
        print(f"Processing file: {bucket}/{key}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
        try:
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±å–å¾—
            response = s3.head_object(Bucket=bucket, Key=key)
            file_size = response['ContentLength']
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            s3.copy_object(
                Bucket=bucket,
                Key=key,
                CopySource={'Bucket': bucket, 'Key': key},
                Metadata={
                    'processed': 'true',
                    'processed_at': datetime.now().isoformat(),
                    'file_size': str(file_size)
                },
                MetadataDirective='REPLACE'
            )
            
            return {
                'statusCode': 200,
                'body': json.dumps(f'Successfully processed {key}')
            }
            
        except Exception as e:
            print(f"Error processing {key}: {str(e)}")
            return {
                'statusCode': 500,
                'body': json.dumps(f'Error processing {key}')
            }
'''
        
        # Lambdaè¨­å®š
        lambda_config = {
            'FunctionName': 's3-file-processor',
            'Runtime': 'python3.9',
            'Role': 'arn:aws:iam::123456789012:role/lambda-execution-role',
            'Handler': 'lambda_function.lambda_handler',
            'Code': {'ZipFile': lambda_code.encode()},
            'Timeout': 300,
            'MemorySize': 512,
            'Environment': {
                'Variables': {
                    'LOG_LEVEL': 'INFO'
                }
            }
        }
        
        print("Lambdaé–¢æ•°è¨­å®š:")
        for key, value in lambda_config.items():
            if key != 'Code':
                print(f"  {key}: {value}")
        
        print("\nLambdaé–¢æ•°ã‚³ãƒ¼ãƒ‰:")
        print(lambda_code)
        
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒˆãƒªã‚¬ãƒ¼è¨­å®š
        trigger_config = '''
# S3ã‚¤ãƒ™ãƒ³ãƒˆãƒˆãƒªã‚¬ãƒ¼è¨­å®š
s3.put_bucket_notification_configuration(
    Bucket='my-bucket',
    NotificationConfiguration={
        'LambdaConfigurations': [
            {
                'Id': 'ProcessNewFiles',
                'LambdaFunctionArn': 'arn:aws:lambda:us-east-1:123456789012:function:s3-file-processor',
                'Events': ['s3:ObjectCreated:*'],
                'Filter': {
                    'Key': {
                        'FilterRules': [
                            {
                                'Name': 'prefix',
                                'Value': 'uploads/'
                            },
                            {
                                'Name': 'suffix',
                                'Value': '.csv'
                            }
                        ]
                    }
                }
            }
        ]
    }
)
'''
        
        print("\nã‚¤ãƒ™ãƒ³ãƒˆãƒˆãƒªã‚¬ãƒ¼è¨­å®š:")
        print(trigger_config)
        
        return lambda_config

# ä½¿ç”¨ä¾‹
cloud_foundations = CloudFoundations()
cloud_models = cloud_foundations.explain_cloud_models()
cloud_foundations.aws_service_overview()

aws_demo = AWSHandsOn()
ec2_config = aws_demo.mock_ec2_operations()
s3_operations = aws_demo.mock_s3_operations()
lambda_config = aws_demo.mock_lambda_function()
```

### 1.2 VPCã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°

```python
class NetworkArchitecture:
    """
    VPCã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°è¨­è¨ˆ
    """
    
    def __init__(self):
        self.vpc_design = {}
        self.security_groups = {}
        self.routing_tables = {}
    
    def design_vpc_architecture(self):
        """VPCã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ"""
        vpc_design = {
            'vpc': {
                'cidr_block': '10.0.0.0/16',
                'enable_dns_hostnames': True,
                'enable_dns_support': True
            },
            'subnets': {
                'public_subnet_1a': {
                    'cidr_block': '10.0.1.0/24',
                    'availability_zone': 'us-east-1a',
                    'map_public_ip_on_launch': True
                },
                'public_subnet_1b': {
                    'cidr_block': '10.0.2.0/24',
                    'availability_zone': 'us-east-1b',
                    'map_public_ip_on_launch': True
                },
                'private_subnet_1a': {
                    'cidr_block': '10.0.3.0/24',
                    'availability_zone': 'us-east-1a',
                    'map_public_ip_on_launch': False
                },
                'private_subnet_1b': {
                    'cidr_block': '10.0.4.0/24',
                    'availability_zone': 'us-east-1b',
                    'map_public_ip_on_launch': False
                }
            },
            'internet_gateway': {
                'attached_to_vpc': True
            },
            'nat_gateway': {
                'subnet': 'public_subnet_1a',
                'elastic_ip': True
            }
        }
        
        print("=== VPCã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ ===")
        print(f"VPC CIDR: {vpc_design['vpc']['cidr_block']}")
        print("\nã‚µãƒ–ãƒãƒƒãƒˆè¨­è¨ˆ:")
        for subnet_name, config in vpc_design['subnets'].items():
            subnet_type = "ãƒ‘ãƒ–ãƒªãƒƒã‚¯" if config['map_public_ip_on_launch'] else "ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ"
            print(f"  {subnet_name} ({subnet_type}): {config['cidr_block']} - {config['availability_zone']}")
        
        # Terraformè¨­å®šä¾‹
        terraform_vpc = '''
# VPCä½œæˆ
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name = "main-vpc"
  }
}

# ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
  
  tags = {
    Name = "main-igw"
  }
}

# ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚µãƒ–ãƒãƒƒãƒˆ
resource "aws_subnet" "public_1a" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.1.0/24"
  availability_zone       = "us-east-1a"
  map_public_ip_on_launch = true
  
  tags = {
    Name = "public-subnet-1a"
  }
}

# ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚µãƒ–ãƒãƒƒãƒˆ
resource "aws_subnet" "private_1a" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.3.0/24"
  availability_zone = "us-east-1a"
  
  tags = {
    Name = "private-subnet-1a"
  }
}

# NATã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤ç”¨Elastic IP
resource "aws_eip" "nat" {
  domain = "vpc"
  
  tags = {
    Name = "nat-eip"
  }
}

# NATã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤
resource "aws_nat_gateway" "main" {
  allocation_id = aws_eip.nat.id
  subnet_id     = aws_subnet.public_1a.id
  
  tags = {
    Name = "main-nat"
  }
}
'''
        
        print("\nTerraformè¨­å®šä¾‹:")
        print(terraform_vpc)
        
        self.vpc_design = vpc_design
        return vpc_design
    
    def design_security_groups(self):
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—è¨­è¨ˆ"""
        security_groups = {
            'web_server_sg': {
                'description': 'Security group for web servers',
                'ingress_rules': [
                    {
                        'protocol': 'tcp',
                        'port': 80,
                        'source': '0.0.0.0/0',
                        'description': 'HTTP access from internet'
                    },
                    {
                        'protocol': 'tcp',
                        'port': 443,
                        'source': '0.0.0.0/0',
                        'description': 'HTTPS access from internet'
                    },
                    {
                        'protocol': 'tcp',
                        'port': 22,
                        'source': '10.0.0.0/16',
                        'description': 'SSH access from VPC'
                    }
                ],
                'egress_rules': [
                    {
                        'protocol': 'all',
                        'port': 'all',
                        'destination': '0.0.0.0/0',
                        'description': 'All outbound traffic'
                    }
                ]
            },
            'database_sg': {
                'description': 'Security group for database servers',
                'ingress_rules': [
                    {
                        'protocol': 'tcp',
                        'port': 3306,
                        'source_sg': 'web_server_sg',
                        'description': 'MySQL access from web servers'
                    },
                    {
                        'protocol': 'tcp',
                        'port': 22,
                        'source_sg': 'bastion_sg',
                        'description': 'SSH access from bastion'
                    }
                ],
                'egress_rules': [
                    {
                        'protocol': 'tcp',
                        'port': 80,
                        'destination': '0.0.0.0/0',
                        'description': 'HTTP for package updates'
                    },
                    {
                        'protocol': 'tcp',
                        'port': 443,
                        'destination': '0.0.0.0/0',
                        'description': 'HTTPS for package updates'
                    }
                ]
            },
            'load_balancer_sg': {
                'description': 'Security group for load balancer',
                'ingress_rules': [
                    {
                        'protocol': 'tcp',
                        'port': 80,
                        'source': '0.0.0.0/0',
                        'description': 'HTTP from internet'
                    },
                    {
                        'protocol': 'tcp',
                        'port': 443,
                        'source': '0.0.0.0/0',
                        'description': 'HTTPS from internet'
                    }
                ]
            }
        }
        
        print("=== ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—è¨­è¨ˆ ===")
        for sg_name, config in security_groups.items():
            print(f"\n{sg_name}:")
            print(f"  èª¬æ˜: {config['description']}")
            print("  ã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒ‰ãƒ«ãƒ¼ãƒ«:")
            for rule in config['ingress_rules']:
                source = rule.get('source', rule.get('source_sg', 'N/A'))
                print(f"    {rule['protocol']}:{rule['port']} <- {source}")
        
        # Terraformè¨­å®šä¾‹
        terraform_sg = '''
resource "aws_security_group" "web_server" {
  name        = "web-server-sg"
  description = "Security group for web servers"
  vpc_id      = aws_vpc.main.id

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["10.0.0.0/16"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = "web-server-sg"
  }
}
'''
        
        print("\nTerraformè¨­å®šä¾‹:")
        print(terraform_sg)
        
        self.security_groups = security_groups
        return security_groups
    
    def network_monitoring_setup(self):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°è¨­å®š"""
        monitoring_config = {
            'vpc_flow_logs': {
                'log_destination': 'CloudWatch Logs',
                'traffic_type': 'ALL',  # ACCEPT, REJECT, ALL
                'log_format': '${srcaddr} ${dstaddr} ${srcport} ${dstport} ${protocol} ${packets} ${bytes} ${start} ${end} ${action}'
            },
            'cloudwatch_metrics': [
                'NetworkIn',
                'NetworkOut',
                'NetworkPacketsIn',
                'NetworkPacketsOut'
            ],
            'alarms': [
                {
                    'name': 'HighNetworkUtilization',
                    'metric': 'NetworkIn',
                    'threshold': 1000000000,  # 1GB
                    'comparison': 'GreaterThanThreshold',
                    'evaluation_periods': 2
                }
            ]
        }
        
        print("=== ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° ===")
        print(f"VPCãƒ•ãƒ­ãƒ¼ãƒ­ã‚°: {monitoring_config['vpc_flow_logs']['traffic_type']}")
        print(f"é€ä¿¡å…ˆ: {monitoring_config['vpc_flow_logs']['log_destination']}")
        print(f"ç›£è¦–ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {', '.join(monitoring_config['cloudwatch_metrics'])}")
        
        # CloudFormation ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¾‹
        cloudformation_template = '''
{
  "AWSTemplateFormatVersion": "2010-09-09",
  "Resources": {
    "VPCFlowLog": {
      "Type": "AWS::EC2::FlowLog",
      "Properties": {
        "ResourceType": "VPC",
        "ResourceId": {"Ref": "VPC"},
        "TrafficType": "ALL",
        "LogDestinationType": "cloud-watch-logs",
        "LogGroupName": "/aws/vpc/flowlogs"
      }
    },
    "NetworkAlarm": {
      "Type": "AWS::CloudWatch::Alarm",
      "Properties": {
        "AlarmName": "HighNetworkUtilization",
        "AlarmDescription": "Alert when network utilization is high",
        "MetricName": "NetworkIn",
        "Namespace": "AWS/EC2",
        "Statistic": "Average",
        "Period": 300,
        "EvaluationPeriods": 2,
        "Threshold": 1000000000,
        "ComparisonOperator": "GreaterThanThreshold"
      }
    }
  }
}
'''
        
        print("\nCloudFormationãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¾‹:")
        print(cloudformation_template)
        
        return monitoring_config

# ä½¿ç”¨ä¾‹
network_arch = NetworkArchitecture()
vpc_design = network_arch.design_vpc_architecture()
security_groups = network_arch.design_security_groups()
monitoring_config = network_arch.network_monitoring_setup()
```

## ğŸ³ Phase 2: Dockerã‚³ãƒ³ãƒ†ãƒŠæŠ€è¡“

### 2.1 DockeråŸºç¤ã‹ã‚‰å®Ÿè·µ

```python
import os
import subprocess

class DockerMastery:
    """
    DockeræŠ€è¡“ã®ç¿’å¾—
    """
    
    def __init__(self):
        self.docker_commands = {}
        self.dockerfiles = {}
        self.compose_files = {}
    
    def docker_fundamentals(self):
        """DockeråŸºç¤æ¦‚å¿µ"""
        concepts = {
            'ã‚³ãƒ³ãƒ†ãƒŠ': 'ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãã®ä¾å­˜é–¢ä¿‚ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–ã—ãŸè»½é‡ãªå®Ÿè¡Œç’°å¢ƒ',
            'ã‚¤ãƒ¡ãƒ¼ã‚¸': 'ã‚³ãƒ³ãƒ†ãƒŠã®è¨­è¨ˆå›³ã€‚èª­ã¿å–ã‚Šå°‚ç”¨ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ',
            'Dockerfile': 'ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®å‘½ä»¤ãƒ•ã‚¡ã‚¤ãƒ«',
            'ãƒ¬ã‚¸ã‚¹ãƒˆãƒª': 'ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä¿å­˜ãƒ»å…±æœ‰ã™ã‚‹ãŸã‚ã®ã‚µãƒ¼ãƒ“ã‚¹ (Docker Hubç­‰)',
            'ãƒœãƒªãƒ¥ãƒ¼ãƒ ': 'ãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–ã¨ã‚³ãƒ³ãƒ†ãƒŠé–“ã§ã®å…±æœ‰ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ',
            'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯': 'ã‚³ãƒ³ãƒ†ãƒŠé–“ã®é€šä¿¡ã‚’ç®¡ç†ã™ã‚‹ä»•çµ„ã¿'
        }
        
        print("=== DockeråŸºç¤æ¦‚å¿µ ===")
        for concept, description in concepts.items():
            print(f"{concept}: {description}")
        
        # åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰é›†
        basic_commands = {
            'ã‚¤ãƒ¡ãƒ¼ã‚¸ç®¡ç†': [
                'docker images                    # ã‚¤ãƒ¡ãƒ¼ã‚¸ä¸€è¦§',
                'docker pull nginx               # ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰',
                'docker build -t myapp .         # ã‚¤ãƒ¡ãƒ¼ã‚¸æ§‹ç¯‰',
                'docker rmi myapp                # ã‚¤ãƒ¡ãƒ¼ã‚¸å‰Šé™¤'
            ],
            'ã‚³ãƒ³ãƒ†ãƒŠç®¡ç†': [
                'docker ps                       # å®Ÿè¡Œä¸­ã‚³ãƒ³ãƒ†ãƒŠä¸€è¦§',
                'docker ps -a                    # å…¨ã‚³ãƒ³ãƒ†ãƒŠä¸€è¦§',
                'docker run -d nginx             # ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•',
                'docker stop container_id        # ã‚³ãƒ³ãƒ†ãƒŠåœæ­¢',
                'docker rm container_id          # ã‚³ãƒ³ãƒ†ãƒŠå‰Šé™¤'
            ],
            'ã‚³ãƒ³ãƒ†ãƒŠæ“ä½œ': [
                'docker exec -it container bash  # ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ',
                'docker logs container_id        # ãƒ­ã‚°ç¢ºèª',
                'docker cp file container:/path  # ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼',
                'docker inspect container_id     # ã‚³ãƒ³ãƒ†ãƒŠè©³ç´°æƒ…å ±'
            ]
        }
        
        print("\n=== åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰ ===")
        for category, commands in basic_commands.items():
            print(f"\n{category}:")
            for command in commands:
                print(f"  {command}")
        
        return concepts, basic_commands
    
    def create_python_app_dockerfile(self):
        """Pythonã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨Dockerfile"""
        dockerfile_content = '''# Pythonã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨Dockerfile
FROM python:3.9-slim

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
WORKDIR /app

# ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ›´æ–°ã¨ãƒ„ãƒ¼ãƒ«è¿½åŠ 
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# ä¾å­˜é–¢ä¿‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
COPY requirements.txt .

# Pythonä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN pip install --no-cache-dir -r requirements.txt

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼
COPY . .

# éç‰¹æ¨©ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ
RUN useradd --create-home --shell /bin/bash app \\
    && chown -R app:app /app
USER app

# ãƒãƒ¼ãƒˆå…¬é–‹
EXPOSE 8000

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•
CMD ["python", "app.py"]
'''
        
        # requirements.txtä¾‹
        requirements_content = '''flask==2.3.2
gunicorn==21.2.0
redis==4.6.0
psycopg2-binary==2.9.7
prometheus_client==0.17.1
'''
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
        app_content = '''from flask import Flask, jsonify
import redis
import os
from prometheus_client import Counter, generate_latest

app = Flask(__name__)

# Redisæ¥ç¶š
redis_client = redis.Redis(
    host=os.getenv('REDIS_HOST', 'localhost'),
    port=int(os.getenv('REDIS_PORT', 6379)),
    db=0
)

# Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests')

@app.route('/')
def hello():
    REQUEST_COUNT.inc()
    try:
        visits = redis_client.incr('visits')
        return jsonify({
            'message': 'Hello from Docker!',
            'visits': visits
        })
    except:
        return jsonify({
            'message': 'Hello from Docker!',
            'visits': 'Redis unavailable'
        })

@app.route('/health')
def health():
    return jsonify({'status': 'healthy'})

@app.route('/metrics')
def metrics():
    return generate_latest()

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000, debug=False)
'''
        
        print("=== Dockerfileä½œæˆä¾‹ ===")
        print(dockerfile_content)
        print("\n=== requirements.txt ===")
        print(requirements_content)
        print("\n=== ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ===")
        print(app_content)
        
        # ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ã®ä¾‹
        multistage_dockerfile = '''# ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ä¾‹
# ãƒ“ãƒ«ãƒ‰ã‚¹ãƒ†ãƒ¼ã‚¸
FROM node:16 AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

# æœ¬ç•ªã‚¹ãƒ†ãƒ¼ã‚¸
FROM node:16-alpine
WORKDIR /app
COPY --from=builder /app/node_modules ./node_modules
COPY . .
EXPOSE 3000
CMD ["npm", "start"]
'''
        
        print("\n=== ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ä¾‹ ===")
        print(multistage_dockerfile)
        
        self.dockerfiles['python_app'] = dockerfile_content
        return dockerfile_content
    
    def create_docker_compose(self):
        """Docker Composeè¨­å®š"""
        compose_content = '''version: '3.8'

services:
  # Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
  web:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DATABASE_URL=postgresql://user:password@db:5432/myapp
    depends_on:
      - redis
      - db
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    networks:
      - app-network

  # Redis ã‚­ãƒ£ãƒƒã‚·ãƒ¥
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - app-network

  # PostgreSQL ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
  db:
    image: postgres:15
    environment:
      POSTGRES_DB: myapp
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped
    networks:
      - app-network

  # Nginx ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - web
    restart: unless-stopped
    networks:
      - app-network

  # Prometheus ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    networks:
      - app-network

  # Grafana ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - app-network

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  app-network:
    driver: bridge
'''
        
        # Nginxè¨­å®š
        nginx_config = '''events {
    worker_connections 1024;
}

http {
    upstream web_backend {
        server web:8000;
    }

    server {
        listen 80;
        server_name localhost;

        location / {
            proxy_pass http://web_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        location /health {
            access_log off;
            proxy_pass http://web_backend/health;
        }
    }
}
'''
        
        # Prometheusè¨­å®š
        prometheus_config = '''global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'web-app'
    static_configs:
      - targets: ['web:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
'''
        
        print("=== Docker Composeè¨­å®š ===")
        print(compose_content)
        print("\n=== Nginxè¨­å®š ===")
        print(nginx_config)
        print("\n=== Prometheusè¨­å®š ===")
        print(prometheus_config)
        
        # Docker Composeã‚³ãƒãƒ³ãƒ‰ä¾‹
        compose_commands = [
            'docker-compose up -d              # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•',
            'docker-compose down               # åœæ­¢ãƒ»å‰Šé™¤',
            'docker-compose logs web           # ç‰¹å®šã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ­ã‚°',
            'docker-compose exec web bash      # ã‚µãƒ¼ãƒ“ã‚¹å†…ã§ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ',
            'docker-compose ps                 # ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª',
            'docker-compose pull               # ã‚¤ãƒ¡ãƒ¼ã‚¸æ›´æ–°',
            'docker-compose build web          # ç‰¹å®šã‚µãƒ¼ãƒ“ã‚¹ã‚’ãƒ“ãƒ«ãƒ‰'
        ]
        
        print("\n=== Docker Composeã‚³ãƒãƒ³ãƒ‰ ===")
        for command in compose_commands:
            print(f"  {command}")
        
        self.compose_files['full_stack'] = compose_content
        return compose_content
    
    def docker_best_practices(self):
        """Dockerãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹"""
        best_practices = {
            'ã‚¤ãƒ¡ãƒ¼ã‚¸æœ€é©åŒ–': [
                'ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›',
                '.dockerignoreãƒ•ã‚¡ã‚¤ãƒ«ã§ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–',
                'è»½é‡ãªãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆalpineç­‰ï¼‰ã‚’ä½¿ç”¨',
                'ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨ã™ã‚‹ãŸã‚ã«å‘½ä»¤é †åºã‚’æœ€é©åŒ–',
                '1ã¤ã®RUNã‚³ãƒãƒ³ãƒ‰ã§è¤‡æ•°ã®æ“ä½œã‚’ã¾ã¨ã‚ã‚‹'
            ],
            'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£': [
                'éç‰¹æ¨©ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ',
                'ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã§ç®¡ç†',
                'å®šæœŸçš„ã«ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ›´æ–°',
                'ä¸è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªã„',
                'ã‚¤ãƒ¡ãƒ¼ã‚¸ã®è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ã‚’å®Ÿæ–½'
            ],
            'é‹ç”¨': [
                'ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’è¨­å®š',
                'ãƒ­ã‚°ã‚’æ¨™æº–å‡ºåŠ›ã«å‡ºåŠ›',
                'ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’é©åˆ‡ã«å®Ÿè£…',
                'ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ã‚’è¨­å®š',
                'ã‚¿ã‚°ã‚’é©åˆ‡ã«ç®¡ç†ï¼ˆlatesté¿ã‘ã‚‹ï¼‰'
            ]
        }
        
        print("=== Dockerãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ ===")
        for category, practices in best_practices.items():
            print(f"\n{category}:")
            for practice in practices:
                print(f"  â€¢ {practice}")
        
        # æœ€é©åŒ–ã•ã‚ŒãŸDockerfileä¾‹
        optimized_dockerfile = '''# æœ€é©åŒ–ã•ã‚ŒãŸDockerfileä¾‹
FROM python:3.9-slim as base

# ãƒ“ãƒ«ãƒ‰æ™‚å¼•æ•°
ARG BUILD_DATE
ARG VERSION
ARG VCS_REF

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
LABEL org.opencontainers.image.created=$BUILD_DATE \\
      org.opencontainers.image.version=$VERSION \\
      org.opencontainers.image.revision=$VCS_REF \\
      org.opencontainers.image.title="My Python App" \\
      org.opencontainers.image.description="Optimized Python application"

# ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚ï¼ˆ1ã¤ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ï¼‰
RUN apt-get update && apt-get install -y --no-install-recommends \\
    gcc \\
    && rm -rf /var/lib/apt/lists/* \\
    && apt-get clean

# Pythonä¾å­˜é–¢ä¿‚ï¼ˆåˆ†é›¢ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡å‘ä¸Šï¼‰
COPY requirements.txt /tmp/
RUN pip install --no-cache-dir --upgrade pip \\
    && pip install --no-cache-dir -r /tmp/requirements.txt \\
    && rm /tmp/requirements.txt

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ
RUN useradd --create-home --shell /bin/bash --uid 1000 app

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ã‚¢ãƒ—ãƒªã‚³ãƒ¼ãƒ‰
WORKDIR /app
COPY --chown=app:app . /app/

# éç‰¹æ¨©ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ‡ã‚Šæ›¿ãˆ
USER 1000

# ãƒãƒ¼ãƒˆå…¬é–‹
EXPOSE 8000

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\
    CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•
CMD ["gunicorn", "--bind", "0.0.0.0:8000", "app:app"]
'''
        
        print("\n=== æœ€é©åŒ–ã•ã‚ŒãŸDockerfile ===")
        print(optimized_dockerfile)
        
        return best_practices

# ä½¿ç”¨ä¾‹
docker_master = DockerMastery()
concepts, commands = docker_master.docker_fundamentals()
dockerfile = docker_master.create_python_app_dockerfile()
compose_config = docker_master.create_docker_compose()
best_practices = docker_master.docker_best_practices()
```

### 2.2 ã‚³ãƒ³ãƒ†ãƒŠã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

```python
class ContainerOrchestration:
    """
    ã‚³ãƒ³ãƒ†ãƒŠã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æŠ€è¡“
    """
    
    def __init__(self):
        self.orchestration_tools = {}
        self.deployment_strategies = {}
    
    def orchestration_comparison(self):
        """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«æ¯”è¼ƒ"""
        tools = {
            'Docker Swarm': {
                'å­¦ç¿’ã‚³ã‚¹ãƒˆ': 'ä½',
                'ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£': 'ä¸­',
                'æ©Ÿèƒ½ã®è±Šå¯Œã•': 'ä¸­',
                'é©ç”¨å ´é¢': 'å°ã€œä¸­è¦æ¨¡ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³',
                'ç‰¹å¾´': ['Dockerã«çµ„ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹', 'è¨­å®šãŒç°¡å˜', 'è»½é‡']
            },
            'Kubernetes': {
                'å­¦ç¿’ã‚³ã‚¹ãƒˆ': 'é«˜',
                'ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£': 'é«˜',
                'æ©Ÿèƒ½ã®è±Šå¯Œã•': 'é«˜',
                'é©ç”¨å ´é¢': 'å¤§è¦æ¨¡ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³',
                'ç‰¹å¾´': ['æ¥­ç•Œæ¨™æº–', 'è±Šå¯Œãªã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ', 'é«˜ã„å¯ç”¨æ€§']
            },
            'Amazon ECS': {
                'å­¦ç¿’ã‚³ã‚¹ãƒˆ': 'ä¸­',
                'ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£': 'é«˜',
                'æ©Ÿèƒ½ã®è±Šå¯Œã•': 'ä¸­',
                'é©ç”¨å ´é¢': 'AWSãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³',
                'ç‰¹å¾´': ['AWSã‚µãƒ¼ãƒ“ã‚¹ã¨ã®çµ±åˆ', 'ãƒãƒãƒ¼ã‚¸ãƒ‰', 'Fargateå¯¾å¿œ']
            },
            'Docker Compose': {
                'å­¦ç¿’ã‚³ã‚¹ãƒˆ': 'ä½',
                'ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£': 'ä½',
                'æ©Ÿèƒ½ã®è±Šå¯Œã•': 'ä½',
                'é©ç”¨å ´é¢': 'é–‹ç™ºç’°å¢ƒã€å˜ä¸€ã‚µãƒ¼ãƒãƒ¼',
                'ç‰¹å¾´': ['ã‚·ãƒ³ãƒ—ãƒ«', 'é–‹ç™ºã«æœ€é©', 'è»½é‡']
            }
        }
        
        print("=== ã‚³ãƒ³ãƒ†ãƒŠã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«æ¯”è¼ƒ ===")
        for tool, features in tools.items():
            print(f"\n{tool}:")
            for feature, value in features.items():
                if feature == 'ç‰¹å¾´':
                    print(f"  {feature}: {', '.join(value)}")
                else:
                    print(f"  {feature}: {value}")
        
        return tools
    
    def docker_swarm_example(self):
        """Docker Swarmå®Ÿè£…ä¾‹"""
        # SwarmåˆæœŸåŒ–
        swarm_commands = [
            '# Swarmã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–',
            'docker swarm init --advertise-addr <MANAGER-IP>',
            '',
            '# ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰è¿½åŠ ',
            'docker swarm join --token <TOKEN> <MANAGER-IP>:2377',
            '',
            '# ãƒãƒ¼ãƒ‰ç¢ºèª',
            'docker node ls',
            '',
            '# ã‚µãƒ¼ãƒ“ã‚¹ä½œæˆ',
            'docker service create --name web --replicas 3 --publish 80:80 nginx',
            '',
            '# ã‚µãƒ¼ãƒ“ã‚¹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°',
            'docker service scale web=5',
            '',
            '# ã‚µãƒ¼ãƒ“ã‚¹ç¢ºèª',
            'docker service ls',
            'docker service ps web'
        ]
        
        # Docker Stackï¼ˆè¤‡æ•°ã‚µãƒ¼ãƒ“ã‚¹ï¼‰
        stack_compose = '''version: '3.8'

services:
  web:
    image: nginx:alpine
    ports:
      - "80:80"
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    networks:
      - web-network

  api:
    image: myapp:latest
    ports:
      - "8000:8000"
    deploy:
      replicas: 2
      placement:
        constraints:
          - node.role == worker
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/myapp
    networks:
      - web-network
      - db-network

  db:
    image: postgres:13
    environment:
      POSTGRES_DB: myapp
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - db-network

volumes:
  db-data:

networks:
  web-network:
    driver: overlay
  db-network:
    driver: overlay
'''
        
        stack_commands = [
            '# Stack ãƒ‡ãƒ—ãƒ­ã‚¤',
            'docker stack deploy -c docker-compose.yml myapp',
            '',
            '# Stack ç¢ºèª',
            'docker stack ls',
            'docker stack services myapp',
            '',
            '# Stack å‰Šé™¤',
            'docker stack rm myapp'
        ]
        
        print("=== Docker Swarm ===")
        print("\n".join(swarm_commands))
        print("\n=== Stack Compose ===")
        print(stack_compose)
        print("\n=== Stack Commands ===")
        print("\n".join(stack_commands))
        
        return {'swarm_commands': swarm_commands, 'stack_compose': stack_compose}
    
    def container_networking(self):
        """ã‚³ãƒ³ãƒ†ãƒŠãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°"""
        networking_concepts = {
            'bridge': 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€‚åŒä¸€ãƒ›ã‚¹ãƒˆå†…ã®ã‚³ãƒ³ãƒ†ãƒŠé€šä¿¡',
            'host': 'ãƒ›ã‚¹ãƒˆã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç›´æ¥ä½¿ç”¨',
            'overlay': 'ãƒãƒ«ãƒãƒ›ã‚¹ãƒˆé–“ã§ã®ã‚³ãƒ³ãƒ†ãƒŠé€šä¿¡ï¼ˆSwarm/Kubernetesï¼‰',
            'none': 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãªã—',
            'custom': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯'
        }
        
        print("=== ã‚³ãƒ³ãƒ†ãƒŠãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¨®é¡ ===")
        for network_type, description in networking_concepts.items():
            print(f"{network_type}: {description}")
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½œæˆä¾‹
        network_examples = '''# ã‚«ã‚¹ã‚¿ãƒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½œæˆ
docker network create --driver bridge my-network

# ã‚µãƒ–ãƒãƒƒãƒˆæŒ‡å®šã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½œæˆ
docker network create \\
  --driver bridge \\
  --subnet=172.20.0.0/16 \\
  --ip-range=172.20.240.0/20 \\
  --gateway=172.20.0.1 \\
  my-custom-network

# ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½œæˆï¼ˆSwarmï¼‰
docker network create --driver overlay --attachable my-overlay

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸€è¦§
docker network ls

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è©³ç´°æƒ…å ±
docker network inspect my-network

# ã‚³ãƒ³ãƒ†ãƒŠã‚’ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«æ¥ç¶š
docker run -d --name web --network my-network nginx
docker network connect my-network existing-container

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ‡æ–­
docker network disconnect my-network container-name
'''
        
        print("\n=== ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ“ä½œä¾‹ ===")
        print(network_examples)
        
        # ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ä¾‹
        service_discovery = '''# Docker Compose ã§ã®ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼
version: '3.8'
services:
  web:
    image: nginx
    # ä»–ã®ã‚µãƒ¼ãƒ“ã‚¹ã‹ã‚‰ "web" ã¨ã„ã†åå‰ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
  
  api:
    image: myapi
    environment:
      # ã‚µãƒ¼ãƒ“ã‚¹åã§ä»–ã®ã‚µãƒ¼ãƒ“ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹
      - DATABASE_URL=postgresql://user:pass@db:5432/myapp
      - REDIS_URL=redis://cache:6379
  
  db:
    image: postgres
  
  cache:
    image: redis
'''
        
        print("\n=== ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ä¾‹ ===")
        print(service_discovery)
        
        return networking_concepts

# ä½¿ç”¨ä¾‹
orchestration = ContainerOrchestration()
tools_comparison = orchestration.orchestration_comparison()
swarm_example = orchestration.docker_swarm_example()
networking = orchestration.container_networking()
```

## â˜¸ï¸ Phase 3: Kuberneteså®Ÿè·µ

### 3.1 KubernetesåŸºç¤

```python
class KubernetesMastery:
    """
    KubernetesæŠ€è¡“ã®ç¿’å¾—
    """
    
    def __init__(self):
        self.k8s_resources = {}
        self.manifests = {}
        self.helm_charts = {}
    
    def kubernetes_architecture(self):
        """Kubernetesã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£"""
        architecture = {
            'Control Plane': {
                'API Server': 'REST APIã‚µãƒ¼ãƒãƒ¼ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®å…¥å£',
                'etcd': 'ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼çŠ¶æ…‹ã‚’ä¿å­˜ã™ã‚‹åˆ†æ•£KVS',
                'Controller Manager': 'ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’å®Ÿè¡Œ',
                'Scheduler': 'Podã‚’Nodeã«é…ç½®ã™ã‚‹'
            },
            'Node Components': {
                'kubelet': 'Nodeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€Podãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†',
                'kube-proxy': 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ—ãƒ­ã‚­ã‚·ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°',
                'Container Runtime': 'ã‚³ãƒ³ãƒ†ãƒŠå®Ÿè¡Œç’°å¢ƒï¼ˆDockerã€containerdç­‰ï¼‰'
            },
            'Add-ons': {
                'DNS': 'ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…åå‰è§£æ±º',
                'Dashboard': 'Web UI',
                'Ingress Controller': 'L7ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼',
                'CNI': 'Container Network Interface'
            }
        }
        
        print("=== Kubernetesã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===")
        for component_type, components in architecture.items():
            print(f"\n{component_type}:")
            for component, description in components.items():
                print(f"  {component}: {description}")
        
        # åŸºæœ¬çš„ãªkubectlã‚³ãƒãƒ³ãƒ‰
        kubectl_commands = [
            '# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æƒ…å ±',
            'kubectl cluster-info',
            'kubectl get nodes',
            '',
            '# ãƒªã‚½ãƒ¼ã‚¹æ“ä½œ',
            'kubectl get pods',
            'kubectl get services',
            'kubectl get deployments',
            'kubectl get all',
            '',
            '# ãƒªã‚½ãƒ¼ã‚¹è©³ç´°',
            'kubectl describe pod <pod-name>',
            'kubectl logs <pod-name>',
            'kubectl exec -it <pod-name> -- /bin/bash',
            '',
            '# ãƒªã‚½ãƒ¼ã‚¹ä½œæˆãƒ»æ›´æ–°',
            'kubectl apply -f deployment.yaml',
            'kubectl create deployment nginx --image=nginx',
            'kubectl expose deployment nginx --port=80 --type=LoadBalancer',
            '',
            '# ãƒªã‚½ãƒ¼ã‚¹å‰Šé™¤',
            'kubectl delete pod <pod-name>',
            'kubectl delete -f deployment.yaml'
        ]
        
        print("\n=== åŸºæœ¬kubectl ã‚³ãƒãƒ³ãƒ‰ ===")
        print("\n".join(kubectl_commands))
        
        return architecture
    
    def create_pod_manifest(self):
        """Pod ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆä½œæˆ"""
        pod_manifest = '''apiVersion: v1
kind: Pod
metadata:
  name: my-app-pod
  namespace: default
  labels:
    app: my-app
    version: v1.0
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
spec:
  # Podã®è¨­å®š
  restartPolicy: Always
  serviceAccountName: my-app-sa
  
  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 2000
  
  # ã‚³ãƒ³ãƒ†ãƒŠå®šç¾©
  containers:
  - name: my-app
    image: my-app:v1.0
    imagePullPolicy: IfNotPresent
    
    # ãƒãƒ¼ãƒˆè¨­å®š
    ports:
    - containerPort: 8080
      name: http
      protocol: TCP
    
    # ç’°å¢ƒå¤‰æ•°
    env:
    - name: DATABASE_URL
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: url
    - name: REDIS_HOST
      value: "redis-service"
    - name: LOG_LEVEL
      value: "INFO"
    
    # ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
    
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 3
    
    # ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒã‚¦ãƒ³ãƒˆ
    volumeMounts:
    - name: config-volume
      mountPath: /etc/config
      readOnly: true
    - name: data-volume
      mountPath: /data
  
  # ã‚µã‚¤ãƒ‰ã‚«ãƒ¼ã‚³ãƒ³ãƒ†ãƒŠï¼ˆãƒ­ã‚°åé›†ï¼‰
  - name: log-collector
    image: fluent/fluent-bit:latest
    volumeMounts:
    - name: log-volume
      mountPath: /var/log
    - name: fluent-bit-config
      mountPath: /fluent-bit/etc
  
  # ãƒœãƒªãƒ¥ãƒ¼ãƒ å®šç¾©
  volumes:
  - name: config-volume
    configMap:
      name: my-app-config
  - name: data-volume
    persistentVolumeClaim:
      claimName: my-app-pvc
  - name: log-volume
    emptyDir: {}
  - name: fluent-bit-config
    configMap:
      name: fluent-bit-config
  
  # ãƒãƒ¼ãƒ‰é¸æŠ
  nodeSelector:
    node-type: worker
  
  # Tolerationï¼ˆæ±šæŸ“ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã§ã‚‚å®Ÿè¡Œå¯èƒ½ï¼‰
  tolerations:
  - key: "app"
    operator: "Equal"
    value: "my-app"
    effect: "NoSchedule"
'''
        
        print("=== Pod ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ ===")
        print(pod_manifest)
        
        self.manifests['pod'] = pod_manifest
        return pod_manifest
    
    def create_deployment_manifest(self):
        """Deployment ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆä½œæˆ"""
        deployment_manifest = '''apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app-deployment
  namespace: default
  labels:
    app: my-app
spec:
  # ãƒ¬ãƒ—ãƒªã‚«æ•°
  replicas: 3
  
  # ã‚»ãƒ¬ã‚¯ã‚¿
  selector:
    matchLabels:
      app: my-app
  
  # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  
  # Pod ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
  template:
    metadata:
      labels:
        app: my-app
        version: v1.0
    spec:
      containers:
      - name: my-app
        image: my-app:v1.0
        ports:
        - containerPort: 8080
        
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
        
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
  labels:
    app: my-app
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
    name: http
  selector:
    app: my-app
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-app-config
data:
  app.properties: |
    server.port=8080
    logging.level.root=INFO
    spring.profiles.active=production
  
  nginx.conf: |
    server {
        listen 80;
        location / {
            proxy_pass http://localhost:8080;
        }
    }
---
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
data:
  # base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿
  url: cG9zdGdyZXNxbDovL3VzZXI6cGFzc0BkYjozNDUyL215YXBw
  username: dXNlcg==
  password: cGFzcw==
'''
        
        print("=== Deployment ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ ===")
        print(deployment_manifest)
        
        self.manifests['deployment'] = deployment_manifest
        return deployment_manifest
    
    def create_ingress_manifest(self):
        """Ingress ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆä½œæˆ"""
        ingress_manifest = '''apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-app-ingress
  annotations:
    # Nginx Ingress Controllerè¨­å®š
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    
    # SSL/TLSè¨­å®š
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    
    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    
    # CORSè¨­å®š
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-methods: "GET, PUT, POST, DELETE, PATCH, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-headers: "DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization"
spec:
  tls:
  - hosts:
    - my-app.example.com
    secretName: my-app-tls
  
  rules:
  - host: my-app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: my-app-service
            port:
              number: 80
      
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: my-app-api-service
            port:
              number: 8080
  
  - host: admin.my-app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: my-app-admin-service
            port:
              number: 3000
---
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@example.com
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: nginx
'''
        
        print("=== Ingress ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ ===")
        print(ingress_manifest)
        
        self.manifests['ingress'] = ingress_manifest
        return ingress_manifest
    
    def create_hpa_manifest(self):
        """Horizontal Pod Autoscaler ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ"""
        hpa_manifest = '''apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app-deployment
  
  minReplicas: 2
  maxReplicas: 10
  
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  
  # ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆä¾‹ï¼šãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ï¼‰
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"
  
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 2
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
---
apiVersion: v1
kind: ServiceMonitor
metadata:
  name: my-app-monitor
spec:
  selector:
    matchLabels:
      app: my-app
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
'''
        
        print("=== HPA ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ ===")
        print(hpa_manifest)
        
        self.manifests['hpa'] = hpa_manifest
        return hpa_manifest

# ä½¿ç”¨ä¾‹
k8s_master = KubernetesMastery()
architecture = k8s_master.kubernetes_architecture()
pod_manifest = k8s_master.create_pod_manifest()
deployment_manifest = k8s_master.create_deployment_manifest()
ingress_manifest = k8s_master.create_ingress_manifest()
hpa_manifest = k8s_master.create_hpa_manifest()
```

### 3.2 Helmãƒãƒ£ãƒ¼ãƒˆã¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†

```python
class HelmMastery:
    """
    Helmãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†ã®ç¿’å¾—
    """
    
    def __init__(self):
        self.charts = {}
        self.values = {}
    
    def helm_fundamentals(self):
        """HelmåŸºç¤æ¦‚å¿µ"""
        concepts = {
            'Chart': 'Kubernetesã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸',
            'Release': 'ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸChartã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹',
            'Repository': 'Chartã‚’ä¿å­˜ãƒ»å…±æœ‰ã™ã‚‹å ´æ‰€',
            'Values': 'Chartã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºè¨­å®š',
            'Template': 'Kubernetesãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ',
            'Hook': 'ãƒªãƒªãƒ¼ã‚¹ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ä¸­ã®å‡¦ç†'
        }
        
        print("=== HelmåŸºç¤æ¦‚å¿µ ===")
        for concept, description in concepts.items():
            print(f"{concept}: {description}")
        
        # åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰
        helm_commands = [
            '# ãƒªãƒã‚¸ãƒˆãƒªç®¡ç†',
            'helm repo add stable https://charts.helm.sh/stable',
            'helm repo update',
            'helm repo list',
            'helm search repo nginx',
            '',
            '# ãƒãƒ£ãƒ¼ãƒˆæ“ä½œ',
            'helm install my-release stable/nginx',
            'helm list',
            'helm status my-release',
            'helm upgrade my-release stable/nginx',
            'helm rollback my-release 1',
            'helm uninstall my-release',
            '',
            '# ãƒãƒ£ãƒ¼ãƒˆé–‹ç™º',
            'helm create my-chart',
            'helm lint my-chart',
            'helm template my-chart',
            'helm package my-chart',
            '',
            '# Values ãƒ•ã‚¡ã‚¤ãƒ«',
            'helm install my-release my-chart -f values.yaml',
            'helm install my-release my-chart --set image.tag=v2.0'
        ]
        
        print("\n=== åŸºæœ¬Helmã‚³ãƒãƒ³ãƒ‰ ===")
        print("\n".join(helm_commands))
        
        return concepts
    
    def create_helm_chart(self):
        """Helmãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
        # Chart.yaml
        chart_yaml = '''apiVersion: v2
name: my-app
description: A Helm chart for my application
type: application
version: 0.1.0
appVersion: "1.0"

maintainers:
  - name: Your Name
    email: your.email@example.com

keywords:
  - web
  - api
  - microservice

home: https://my-app.example.com
sources:
  - https://github.com/example/my-app

dependencies:
  - name: postgresql
    version: "^11.0.0"
    repository: "https://charts.bitnami.com/bitnami"
    condition: postgresql.enabled
  
  - name: redis
    version: "^16.0.0"
    repository: "https://charts.bitnami.com/bitnami"
    condition: redis.enabled
'''
        
        # values.yaml
        values_yaml = '''# Default values for my-app
replicaCount: 3

image:
  repository: my-app
  pullPolicy: IfNotPresent
  tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations: {}

podSecurityContext:
  fsGroup: 2000

securityContext:
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000

service:
  type: ClusterIP
  port: 80
  targetPort: 8080

ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "100"
  hosts:
    - host: my-app.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: my-app-tls
      hosts:
        - my-app.example.com

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 128Mi

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
config:
  logLevel: INFO
  database:
    host: ""
    port: 5432
    name: myapp
  redis:
    host: ""
    port: 6379

# ä¾å­˜ã‚µãƒ¼ãƒ“ã‚¹è¨­å®š
postgresql:
  enabled: true
  auth:
    postgresPassword: "changeme"
    database: "myapp"

redis:
  enabled: true
  auth:
    enabled: false

# ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
monitoring:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 30s
    path: /metrics
'''
        
        # deployment.yaml template
        deployment_template = '''apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "my-app.fullname" . }}
  labels:
    {{- include "my-app.labels" . | nindent 4 }}
spec:
  {{- if not .Values.autoscaling.enabled }}
  replicas: {{ .Values.replicaCount }}
  {{- end }}
  selector:
    matchLabels:
      {{- include "my-app.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      {{- with .Values.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "my-app.selectorLabels" . | nindent 8 }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "my-app.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      containers:
        - name: {{ .Chart.Name }}
          securityContext:
            {{- toYaml .Values.securityContext | nindent 12 }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - name: http
              containerPort: {{ .Values.service.targetPort }}
              protocol: TCP
          env:
            - name: LOG_LEVEL
              value: {{ .Values.config.logLevel }}
            - name: DATABASE_URL
              value: "postgresql://postgres:{{ .Values.postgresql.auth.postgresPassword }}@{{ include "my-app.fullname" . }}-postgresql:{{ .Values.config.database.port }}/{{ .Values.config.database.name }}"
            {{- if .Values.redis.enabled }}
            - name: REDIS_URL
              value: "redis://{{ include "my-app.fullname" . }}-redis-master:{{ .Values.config.redis.port }}"
            {{- end }}
          livenessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /ready
              port: http
            initialDelaySeconds: 5
            periodSeconds: 5
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
'''
        
        # _helpers.tpl
        helpers_template = '''{{/*
Expand the name of the chart.
*/}}
{{- define "my-app.name" -}}
{{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix "-" }}
{{- end }}

{{/*
Create a default fully qualified app name.
*/}}
{{- define "my-app.fullname" -}}
{{- if .Values.fullnameOverride }}
{{- .Values.fullnameOverride | trunc 63 | trimSuffix "-" }}
{{- else }}
{{- $name := default .Chart.Name .Values.nameOverride }}
{{- if contains $name .Release.Name }}
{{- .Release.Name | trunc 63 | trimSuffix "-" }}
{{- else }}
{{- printf "%s-%s" .Release.Name $name | trunc 63 | trimSuffix "-" }}
{{- end }}
{{- end }}
{{- end }}

{{/*
Create chart name and version as used by the chart label.
*/}}
{{- define "my-app.chart" -}}
{{- printf "%s-%s" .Chart.Name .Chart.Version | replace "+" "_" | trunc 63 | trimSuffix "-" }}
{{- end }}

{{/*
Common labels
*/}}
{{- define "my-app.labels" -}}
helm.sh/chart: {{ include "my-app.chart" . }}
{{ include "my-app.selectorLabels" . }}
{{- if .Chart.AppVersion }}
app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
{{- end }}
app.kubernetes.io/managed-by: {{ .Release.Service }}
{{- end }}

{{/*
Selector labels
*/}}
{{- define "my-app.selectorLabels" -}}
app.kubernetes.io/name: {{ include "my-app.name" . }}
app.kubernetes.io/instance: {{ .Release.Name }}
{{- end }}

{{/*
Create the name of the service account to use
*/}}
{{- define "my-app.serviceAccountName" -}}
{{- if .Values.serviceAccount.create }}
{{- default (include "my-app.fullname" .) .Values.serviceAccount.name }}
{{- else }}
{{- default "default" .Values.serviceAccount.name }}
{{- end }}
{{- end }}
'''
        
        print("=== Chart.yaml ===")
        print(chart_yaml)
        print("\n=== values.yaml ===")
        print(values_yaml)
        print("\n=== deployment.yaml template ===")
        print(deployment_template)
        print("\n=== _helpers.tpl ===")
        print(helpers_template)
        
        return {
            'chart_yaml': chart_yaml,
            'values_yaml': values_yaml,
            'deployment_template': deployment_template,
            'helpers_template': helpers_template
        }
    
    def helm_advanced_features(self):
        """Helmé«˜åº¦ãªæ©Ÿèƒ½"""
        # Hooksä¾‹
        hooks_example = '''apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ include "my-app.fullname" . }}-db-migration"
  labels:
    {{- include "my-app.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": pre-upgrade,pre-install
    "helm.sh/hook-weight": "-5"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    metadata:
      name: "{{ include "my-app.fullname" . }}-db-migration"
    spec:
      restartPolicy: Never
      containers:
      - name: db-migration
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        command: ["python", "manage.py", "migrate"]
        env:
        - name: DATABASE_URL
          value: "postgresql://postgres:{{ .Values.postgresql.auth.postgresPassword }}@{{ include "my-app.fullname" . }}-postgresql:5432/{{ .Values.config.database.name }}"
'''
        
        # Testsä¾‹
        test_example = '''apiVersion: v1
kind: Pod
metadata:
  name: "{{ include "my-app.fullname" . }}-test"
  labels:
    {{- include "my-app.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": test
spec:
  restartPolicy: Never
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['{{ include "my-app.fullname" . }}:{{ .Values.service.port }}/health']
'''
        
        # ã‚«ã‚¹ã‚¿ãƒ Valuesä¾‹
        custom_values = '''# production-values.yaml
replicaCount: 5

image:
  tag: "v1.2.3"

resources:
  limits:
    cpu: 1000m
    memory: 1Gi
  requests:
    cpu: 200m
    memory: 256Mi

ingress:
  hosts:
    - host: my-app.production.com
      paths:
        - path: /
          pathType: Prefix

postgresql:
  auth:
    postgresPassword: "super-secure-password"
  primary:
    persistence:
      size: 20Gi
      storageClass: "fast-ssd"

monitoring:
  enabled: true
  serviceMonitor:
    enabled: true

# æœ¬ç•ªç’°å¢ƒå›ºæœ‰ã®è¨­å®š
config:
  logLevel: WARN
  database:
    maxConnections: 100
  cache:
    ttl: 3600
'''
        
        print("=== Helm Hooksä¾‹ ===")
        print(hooks_example)
        print("\n=== Testä¾‹ ===")
        print(test_example)
        print("\n=== ã‚«ã‚¹ã‚¿ãƒ Valuesä¾‹ ===")
        print(custom_values)
        
        # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚³ãƒãƒ³ãƒ‰ä¾‹
        deployment_commands = [
            '# é–‹ç™ºç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤',
            'helm install my-app ./my-app --namespace dev --create-namespace',
            '',
            '# æœ¬ç•ªç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤',
            'helm install my-app ./my-app -f production-values.yaml --namespace prod',
            '',
            '# ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰',
            'helm upgrade my-app ./my-app --set image.tag=v1.2.4',
            '',
            '# ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³',
            'helm install my-app ./my-app --dry-run --debug',
            '',
            '# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ',
            'helm test my-app',
            '',
            '# ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯',
            'helm rollback my-app 1'
        ]
        
        print("\n=== ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚³ãƒãƒ³ãƒ‰ä¾‹ ===")
        print("\n".join(deployment_commands))
        
        return {
            'hooks': hooks_example,
            'tests': test_example,
            'custom_values': custom_values
        }

# ä½¿ç”¨ä¾‹
helm_master = HelmMastery()
helm_concepts = helm_master.helm_fundamentals()
helm_chart = helm_master.create_helm_chart()
advanced_features = helm_master.helm_advanced_features()
```

## ğŸ—ï¸ Phase 4: Infrastructure as Code (IaC)

### 4.1 Terraformã«ã‚ˆã‚‹ã‚¤ãƒ³ãƒ•ãƒ©è‡ªå‹•åŒ–

```python
class TerraformMastery:
    """
    Terraformã«ã‚ˆã‚‹ã‚¤ãƒ³ãƒ•ãƒ©è‡ªå‹•åŒ–
    """
    
    def __init__(self):
        self.terraform_configs = {}
        self.modules = {}
    
    def terraform_fundamentals(self):
        """TerraformåŸºç¤æ¦‚å¿µ"""
        concepts = {
            'Provider': 'ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ã®æ¥ç¶šã‚’å®šç¾©',
            'Resource': 'ä½œæˆãƒ»ç®¡ç†ã™ã‚‹ã‚¤ãƒ³ãƒ•ãƒ©ãƒªã‚½ãƒ¼ã‚¹',
            'Data Source': 'æ—¢å­˜ãƒªã‚½ãƒ¼ã‚¹ã®æƒ…å ±ã‚’å–å¾—',
            'Variable': 'è¨­å®šã®å¤‰æ•°åŒ–',
            'Output': 'ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ä½¿ç”¨ã™ã‚‹å€¤ã‚’å‡ºåŠ›',
            'State': 'ã‚¤ãƒ³ãƒ•ãƒ©ã®ç¾åœ¨çŠ¶æ…‹ã‚’ä¿å­˜',
            'Module': 'å†åˆ©ç”¨å¯èƒ½ãªè¨­å®šã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸'
        }
        
        print("=== TerraformåŸºç¤æ¦‚å¿µ ===")
        for concept, description in concepts.items():
            print(f"{concept}: {description}")
        
        # åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰
        terraform_commands = [
            '# åˆæœŸåŒ–',
            'terraform init',
            '',
            '# è¨ˆç”»è¡¨ç¤º',
            'terraform plan',
            '',
            '# é©ç”¨',
            'terraform apply',
            '',
            '# çŠ¶æ…‹ç¢ºèª',
            'terraform show',
            'terraform state list',
            '',
            '# ç ´æ£„',
            'terraform destroy',
            '',
            '# ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ',
            'terraform fmt',
            '',
            '# æ¤œè¨¼',
            'terraform validate'
        ]
        
        print("\n=== åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰ ===")
        print("\n".join(terraform_commands))
        
        return concepts
    
    def create_aws_infrastructure(self):
        """AWS ã‚¤ãƒ³ãƒ•ãƒ©æ§‹ç¯‰ä¾‹"""
        # main.tf
        main_tf = '''# Terraformè¨­å®š
terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
  
  backend "s3" {
    bucket = "my-terraform-state-bucket"
    key    = "prod/terraform.tfstate"
    region = "us-east-1"
    
    dynamodb_table = "terraform-state-lock"
    encrypt        = true
  }
}

# ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
provider "aws" {
  region = var.aws_region
  
  default_tags {
    tags = {
      Environment = var.environment
      Project     = var.project_name
      ManagedBy   = "terraform"
    }
  }
}

# VPC
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name = "${var.project_name}-vpc"
  }
}

# ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
  
  tags = {
    Name = "${var.project_name}-igw"
  }
}

# ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚µãƒ–ãƒãƒƒãƒˆ
resource "aws_subnet" "public" {
  count = length(var.availability_zones)
  
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(var.vpc_cidr, 8, count.index)
  availability_zone       = var.availability_zones[count.index]
  map_public_ip_on_launch = true
  
  tags = {
    Name = "${var.project_name}-public-subnet-${count.index + 1}"
    Type = "public"
  }
}

# ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚µãƒ–ãƒãƒƒãƒˆ
resource "aws_subnet" "private" {
  count = length(var.availability_zones)
  
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index + length(var.availability_zones))
  availability_zone = var.availability_zones[count.index]
  
  tags = {
    Name = "${var.project_name}-private-subnet-${count.index + 1}"
    Type = "private"
  }
}

# Elastic IP for NAT Gateway
resource "aws_eip" "nat" {
  count = length(var.availability_zones)
  
  domain = "vpc"
  
  tags = {
    Name = "${var.project_name}-nat-eip-${count.index + 1}"
  }
  
  depends_on = [aws_internet_gateway.main]
}

# NAT Gateway
resource "aws_nat_gateway" "main" {
  count = length(var.availability_zones)
  
  allocation_id = aws_eip.nat[count.index].id
  subnet_id     = aws_subnet.public[count.index].id
  
  tags = {
    Name = "${var.project_name}-nat-${count.index + 1}"
  }
}

# ãƒ«ãƒ¼ãƒˆãƒ†ãƒ¼ãƒ–ãƒ« - ãƒ‘ãƒ–ãƒªãƒƒã‚¯
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }
  
  tags = {
    Name = "${var.project_name}-public-rt"
  }
}

# ãƒ«ãƒ¼ãƒˆãƒ†ãƒ¼ãƒ–ãƒ« - ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ
resource "aws_route_table" "private" {
  count = length(var.availability_zones)
  
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = aws_nat_gateway.main[count.index].id
  }
  
  tags = {
    Name = "${var.project_name}-private-rt-${count.index + 1}"
  }
}

# ãƒ«ãƒ¼ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«é–¢é€£ä»˜ã‘
resource "aws_route_table_association" "public" {
  count = length(aws_subnet.public)
  
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}

resource "aws_route_table_association" "private" {
  count = length(aws_subnet.private)
  
  subnet_id      = aws_subnet.private[count.index].id
  route_table_id = aws_route_table.private[count.index].id
}
'''
        
        # variables.tf
        variables_tf = '''variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}

variable "environment" {
  description = "Environment name"
  type        = string
  default     = "dev"
  
  validation {
    condition     = contains(["dev", "staging", "prod"], var.environment)
    error_message = "Environment must be dev, staging, or prod."
  }
}

variable "project_name" {
  description = "Project name"
  type        = string
  default     = "my-app"
}

variable "vpc_cidr" {
  description = "CIDR block for VPC"
  type        = string
  default     = "10.0.0.0/16"
  
  validation {
    condition     = can(cidrhost(var.vpc_cidr, 0))
    error_message = "VPC CIDR must be a valid IPv4 CIDR block."
  }
}

variable "availability_zones" {
  description = "List of availability zones"
  type        = list(string)
  default     = ["us-east-1a", "us-east-1b"]
}

variable "instance_type" {
  description = "EC2 instance type"
  type        = string
  default     = "t3.micro"
}

variable "key_name" {
  description = "EC2 Key Pair name"
  type        = string
  default     = ""
}

variable "allowed_cidr_blocks" {
  description = "CIDR blocks allowed to access resources"
  type        = list(string)
  default     = ["0.0.0.0/0"]
}
'''
        
        # outputs.tf
        outputs_tf = '''output "vpc_id" {
  description = "ID of the VPC"
  value       = aws_vpc.main.id
}

output "vpc_cidr_block" {
  description = "CIDR block of the VPC"
  value       = aws_vpc.main.cidr_block
}

output "public_subnet_ids" {
  description = "IDs of the public subnets"
  value       = aws_subnet.public[*].id
}

output "private_subnet_ids" {
  description = "IDs of the private subnets"
  value       = aws_subnet.private[*].id
}

output "internet_gateway_id" {
  description = "ID of the Internet Gateway"
  value       = aws_internet_gateway.main.id
}

output "nat_gateway_ids" {
  description = "IDs of the NAT Gateways"
  value       = aws_nat_gateway.main[*].id
}

output "nat_gateway_ips" {
  description = "Elastic IPs of the NAT Gateways"
  value       = aws_eip.nat[*].public_ip
}
'''
        
        print("=== main.tf ===")
        print(main_tf)
        print("\n=== variables.tf ===")
        print(variables_tf)
        print("\n=== outputs.tf ===")
        print(outputs_tf)
        
        return {
            'main_tf': main_tf,
            'variables_tf': variables_tf,
            'outputs_tf': outputs_tf
        }
    
    def create_terraform_modules(self):
        """Terraformãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ"""
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ ä¾‹
        module_structure = '''
modules/
â”œâ”€â”€ networking/
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ outputs.tf
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ compute/
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ outputs.tf
â”‚   â””â”€â”€ README.md
â””â”€â”€ database/
    â”œâ”€â”€ main.tf
    â”œâ”€â”€ variables.tf
    â”œâ”€â”€ outputs.tf
    â””â”€â”€ README.md
'''
        
        # EKSãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¾‹
        eks_module = '''# modules/eks/main.tf
resource "aws_eks_cluster" "main" {
  name     = var.cluster_name
  role_arn = aws_iam_role.cluster.arn
  version  = var.kubernetes_version
  
  vpc_config {
    subnet_ids              = var.subnet_ids
    endpoint_private_access = var.endpoint_private_access
    endpoint_public_access  = var.endpoint_public_access
    public_access_cidrs     = var.public_access_cidrs
  }
  
  encryption_config {
    provider {
      key_arn = var.kms_key_arn
    }
    resources = ["secrets"]
  }
  
  enabled_cluster_log_types = var.cluster_log_types
  
  depends_on = [
    aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy,
  ]
  
  tags = var.tags
}

resource "aws_eks_node_group" "main" {
  cluster_name    = aws_eks_cluster.main.name
  node_group_name = "${var.cluster_name}-node-group"
  node_role_arn   = aws_iam_role.node_group.arn
  subnet_ids      = var.private_subnet_ids
  
  instance_types = var.node_instance_types
  capacity_type  = var.capacity_type
  
  scaling_config {
    desired_size = var.desired_capacity
    max_size     = var.max_capacity
    min_size     = var.min_capacity
  }
  
  update_config {
    max_unavailable = var.max_unavailable
  }
  
  remote_access {
    ec2_ssh_key = var.key_name
    source_security_group_ids = var.ssh_security_group_ids
  }
  
  depends_on = [
    aws_iam_role_policy_attachment.node_group_AmazonEKSWorkerNodePolicy,
    aws_iam_role_policy_attachment.node_group_AmazonEKS_CNI_Policy,
    aws_iam_role_policy_attachment.node_group_AmazonEC2ContainerRegistryReadOnly,
  ]
  
  tags = var.tags
}

# IAM Role for EKS Cluster
resource "aws_iam_role" "cluster" {
  name = "${var.cluster_name}-cluster-role"
  
  assume_role_policy = jsonencode({
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "eks.amazonaws.com"
      }
    }]
    Version = "2012-10-17"
  })
}

resource "aws_iam_role_policy_attachment" "cluster_AmazonEKSClusterPolicy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
  role       = aws_iam_role.cluster.name
}

# IAM Role for EKS Node Group
resource "aws_iam_role" "node_group" {
  name = "${var.cluster_name}-node-group-role"
  
  assume_role_policy = jsonencode({
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "ec2.amazonaws.com"
      }
    }]
    Version = "2012-10-17"
  })
}

resource "aws_iam_role_policy_attachment" "node_group_AmazonEKSWorkerNodePolicy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
  role       = aws_iam_role.node_group.name
}

resource "aws_iam_role_policy_attachment" "node_group_AmazonEKS_CNI_Policy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
  role       = aws_iam_role.node_group.name
}

resource "aws_iam_role_policy_attachment" "node_group_AmazonEC2ContainerRegistryReadOnly" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
  role       = aws_iam_role.node_group.name
}
'''
        
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ä¾‹
        module_usage = '''# æœ¬ä½“ã®main.tfã§ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨
module "vpc" {
  source = "./modules/networking"
  
  vpc_cidr           = var.vpc_cidr
  availability_zones = var.availability_zones
  project_name       = var.project_name
  environment        = var.environment
}

module "eks" {
  source = "./modules/eks"
  
  cluster_name        = "${var.project_name}-${var.environment}"
  kubernetes_version  = "1.27"
  subnet_ids          = module.vpc.public_subnet_ids
  private_subnet_ids  = module.vpc.private_subnet_ids
  
  node_instance_types = ["t3.medium"]
  desired_capacity    = 3
  max_capacity        = 10
  min_capacity        = 1
  
  tags = {
    Environment = var.environment
    Project     = var.project_name
  }
}

module "monitoring" {
  source = "./modules/monitoring"
  
  cluster_name = module.eks.cluster_name
  vpc_id       = module.vpc.vpc_id
  subnet_ids   = module.vpc.private_subnet_ids
}
'''
        
        print("=== ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€  ===")
        print(module_structure)
        print("\n=== EKSãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¾‹ ===")
        print(eks_module)
        print("\n=== ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ä¾‹ ===")
        print(module_usage)
        
        return {
            'module_structure': module_structure,
            'eks_module': eks_module,
            'module_usage': module_usage
        }
    
    def terraform_best_practices(self):
        """Terraformãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹"""
        best_practices = {
            'ã‚³ãƒ¼ãƒ‰æ§‹æˆ': [
                'ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦å†åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ',
                'ç’°å¢ƒã”ã¨ã«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åˆ†é›¢',
                'å¤‰æ•°ã¨ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’é©åˆ‡ã«å®šç¾©',
                'ãƒªã‚½ãƒ¼ã‚¹ã®å‘½åè¦å‰‡ã‚’çµ±ä¸€',
                'ã‚¿ã‚°ä»˜ã‘ãƒ«ãƒ¼ãƒ«ã‚’å¾¹åº•'
            ],
            'Stateç®¡ç†': [
                'ãƒªãƒ¢ãƒ¼ãƒˆBackendï¼ˆS3 + DynamoDBï¼‰ã‚’ä½¿ç”¨',
                'State ãƒ•ã‚¡ã‚¤ãƒ«ã®æš—å·åŒ–ã‚’æœ‰åŠ¹åŒ–',
                'State ãƒ­ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ç«¶åˆã‚’é˜²æ­¢',
                'é©åˆ‡ãªãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚’ä½¿ç”¨',
                'å®šæœŸçš„ãªState ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—'
            ],
            'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£': [
                'IAMãƒ­ãƒ¼ãƒ«ã®æœ€å°æ¨©é™ã®åŸå‰‡',
                'ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæƒ…å ±ã‚’ã‚³ãƒ¼ãƒ‰ã«å«ã‚ãªã„',
                'Terraformã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«ã®å®‰å…¨ãªç®¡ç†',
                'ãƒªã‚½ãƒ¼ã‚¹ã®æš—å·åŒ–ã‚’æœ‰åŠ¹åŒ–',
                'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—ãƒ«ãƒ¼ãƒ«ã®æœ€å°åŒ–'
            ],
            'é‹ç”¨': [
                'terraform plan ã®çµæœã‚’å¿…ãšç¢ºèª',
                'CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã®è‡ªå‹•åŒ–',
                'ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å¾¹åº•',
                'ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ•´å‚™',
                'ãƒªã‚½ãƒ¼ã‚¹ã®ä¾å­˜é–¢ä¿‚ã‚’ç†è§£'
            ]
        }
        
        print("=== Terraformãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ ===")
        for category, practices in best_practices.items():
            print(f"\n{category}:")
            for practice in practices:
                print(f"  â€¢ {practice}")
        
        # CI/CDä¾‹
        github_actions = '''name: Terraform CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  TF_VERSION: 1.5.0

jobs:
  terraform:
    name: Terraform
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout
      uses: actions/checkout@v3
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: ${{ env.TF_VERSION }}
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Terraform Format
      run: terraform fmt -check
    
    - name: Terraform Init
      run: terraform init
    
    - name: Terraform Validate
      run: terraform validate
    
    - name: Terraform Plan
      run: terraform plan -no-color
      continue-on-error: true
    
    - name: Terraform Apply
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: terraform apply -auto-approve
'''
        
        print("\n=== CI/CDä¾‹ (GitHub Actions) ===")
        print(github_actions)
        
        return best_practices

# ä½¿ç”¨ä¾‹
terraform_master = TerraformMastery()
terraform_concepts = terraform_master.terraform_fundamentals()
aws_infrastructure = terraform_master.create_aws_infrastructure()
terraform_modules = terraform_master.create_terraform_modules()
best_practices = terraform_master.terraform_best_practices()
```

## ğŸ“š ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

ã“ã®ç‰¹å…¸ã§ã¯ã€AIé§†å‹•é–‹ç™ºã«å¿…è¦ãªã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ã‚­ãƒ«ã‚’åŒ…æ‹¬çš„ã«å­¦ç¿’ã—ã¾ã—ãŸã€‚

### ç¿’å¾—ã—ãŸã‚¹ã‚­ãƒ«
âœ… ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°åŸºç¤æ¦‚å¿µ  
âœ… AWSä¸»è¦ã‚µãƒ¼ãƒ“ã‚¹æ´»ç”¨  
âœ… Dockerã‚³ãƒ³ãƒ†ãƒŠæŠ€è¡“  
âœ… Kubernetesã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³  
âœ… Helmãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†  
âœ… Infrastructure as Code (Terraform)  
âœ… ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£  
âœ… ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ­ã‚®ãƒ³ã‚°  

### å®Ÿè·µçš„ãªå­¦ç¿’èª²é¡Œ
1. **ãƒãƒ«ãƒã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒæ§‹ç¯‰**: AWSã€Azureã€GCPã§ã®æ¨ªæ–­çš„ã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†
2. **ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: Kubernetesãƒ™ãƒ¼ã‚¹ã®åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
3. **CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**: GitOpsã‚’æ´»ç”¨ã—ãŸè‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ
4. **ç½å®³å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ **: ãƒãƒ«ãƒãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã§ã®é«˜å¯ç”¨æ€§ã‚¤ãƒ³ãƒ•ãƒ©
5. **ã‚³ã‚¹ãƒˆæœ€é©åŒ–**: ã‚¯ãƒ©ã‚¦ãƒ‰ãƒªã‚½ãƒ¼ã‚¹ã®åŠ¹ç‡çš„ãªé‹ç”¨

### æ¨å¥¨å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹
- **AWS**: AWS Well-Architected Framework
- **Kubernetes**: CNCF Landscape
- **Terraform**: HashiCorp Learn
- **å®Ÿè·µ**: Kubernetes the Hard Way
- **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£**: CNCF, AWS User Groups

ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»ã‚¤ãƒ³ãƒ•ãƒ©æŠ€è¡“ã¯æ€¥é€Ÿã«é€²åŒ–ã—ã¦ã„ã¾ã™ã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€æœ€æ–°æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½ã„ãªãŒã‚‰å®Ÿè·µçš„ãªçµŒé¨“ã‚’ç©ã‚“ã§ã„ãã¾ã—ã‚‡ã†ï¼